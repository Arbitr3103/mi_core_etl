#!/usr/bin/env python3
"""
Ozon Analytics Update Monitor
–°–∏—Å—Ç–µ–º–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –µ–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö Ozon

–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è:
- –ü—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞—Ç—É—Å–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
- –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
- –ê–Ω–∞–ª–∏–∑–∞ –ª–æ–≥–æ–≤
- –û—Ç–ø—Ä–∞–≤–∫–∏ –∞–ª–µ—Ä—Ç–æ–≤

–ê–≤—Ç–æ—Ä: Manhattan System
–í–µ—Ä—Å–∏—è: 1.0
"""

import os
import sys
import json
import logging
import argparse
from datetime import datetime, timedelta, date
from typing import Dict, List, Optional, Tuple
import mysql.connector
from mysql.connector import Error
import glob
import re

class OzonUpdateMonitor:
    """–ö–ª–∞—Å—Å –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Å–∏—Å—Ç–µ–º—ã –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è Ozon"""
    
    def __init__(self, config_file: str = 'config.py'):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–Ω–∏—Ç–æ—Ä–∞
        
        Args:
            config_file: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        """
        self.config = self._load_config(config_file)
        self.logger = self._setup_logging()
        self.db_connection = None
        
    def _load_config(self, config_file: str) -> Dict:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ —Ñ–∞–π–ª–∞"""
        try:
            sys.path.append(os.path.dirname(os.path.abspath(config_file)))
            config_module = __import__(os.path.splitext(os.path.basename(config_file))[0])
            
            return {
                'database': {
                    'host': getattr(config_module, 'DB_HOST', 'localhost'),
                    'user': getattr(config_module, 'DB_USER', 'root'),
                    'password': getattr(config_module, 'DB_PASSWORD', ''),
                    'database': getattr(config_module, 'DB_NAME', 'manhattan'),
                    'port': getattr(config_module, 'DB_PORT', 3306)
                },
                'monitoring': {
                    'log_dir': getattr(config_module, 'LOG_DIR', 'logs'),
                    'alert_threshold_hours': 168,  # 7 –¥–Ω–µ–π
                    'performance_threshold_minutes': 30
                }
            }
        except Exception as e:
            print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é: {e}")
            return self._get_default_config()
    
    def _get_default_config(self) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –±–∞–∑–æ–≤—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é"""
        return {
            'database': {
                'host': 'localhost',
                'user': 'root',
                'password': '',
                'database': 'manhattan',
                'port': 3306
            },
            'monitoring': {
                'log_dir': 'logs',
                'alert_threshold_hours': 168,
                'performance_threshold_minutes': 30
            }
        }
    
    def _setup_logging(self) -> logging.Logger:
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–∏—Å—Ç–µ–º—ã –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        logger = logging.getLogger('ozon_monitor')
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def connect_database(self) -> bool:
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            self.db_connection = mysql.connector.connect(**self.config['database'])
            if self.db_connection.is_connected():
                return True
        except Error as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return False
    
    def disconnect_database(self):
        """–û—Ç–∫–ª—é—á–µ–Ω–∏–µ –æ—Ç –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        if self.db_connection and self.db_connection.is_connected():
            self.db_connection.close()
    
    def get_last_update_status(self) -> Dict:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        
        Returns:
            Dict —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        """
        status = {
            'funnel_data': {'last_update': None, 'records_count': 0},
            'demographics': {'last_update': None, 'records_count': 0},
            'campaigns': {'last_update': None, 'records_count': 0},
            'overall_status': 'unknown'
        }
        
        if not self.connect_database():
            status['overall_status'] = 'database_error'
            return status
        
        try:
            cursor = self.db_connection.cursor()
            
            # –°—Ç–∞—Ç—É—Å –¥–∞–Ω–Ω—ã—Ö –≤–æ—Ä–æ–Ω–∫–∏
            cursor.execute("""
                SELECT MAX(cached_at) as last_update, COUNT(*) as records_count
                FROM ozon_funnel_data
                WHERE cached_at >= DATE_SUB(NOW(), INTERVAL 7 DAY)
            """)
            result = cursor.fetchone()
            if result:
                status['funnel_data']['last_update'] = result[0]
                status['funnel_data']['records_count'] = result[1]
            
            # –°—Ç–∞—Ç—É—Å –¥–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
            cursor.execute("""
                SELECT MAX(cached_at) as last_update, COUNT(*) as records_count
                FROM ozon_demographics
                WHERE cached_at >= DATE_SUB(NOW(), INTERVAL 7 DAY)
            """)
            result = cursor.fetchone()
            if result:
                status['demographics']['last_update'] = result[0]
                status['demographics']['records_count'] = result[1]
            
            # –°—Ç–∞—Ç—É—Å –¥–∞–Ω–Ω—ã—Ö –∫–∞–º–ø–∞–Ω–∏–π
            cursor.execute("""
                SELECT MAX(cached_at) as last_update, COUNT(*) as records_count
                FROM ozon_campaigns
                WHERE cached_at >= DATE_SUB(NOW(), INTERVAL 7 DAY)
            """)
            result = cursor.fetchone()
            if result:
                status['campaigns']['last_update'] = result[0]
                status['campaigns']['records_count'] = result[1]
            
            cursor.close()
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±—â–∏–π —Å—Ç–∞—Ç—É—Å
            now = datetime.now()
            threshold = now - timedelta(hours=self.config['monitoring']['alert_threshold_hours'])
            
            recent_updates = []
            for data_type in ['funnel_data', 'demographics', 'campaigns']:
                last_update = status[data_type]['last_update']
                if last_update and last_update > threshold:
                    recent_updates.append(data_type)
            
            if len(recent_updates) >= 2:  # –ú–∏–Ω–∏–º—É–º 2 —Ç–∏–ø–∞ –¥–∞–Ω–Ω—ã—Ö –æ–±–Ω–æ–≤–ª–µ–Ω—ã
                status['overall_status'] = 'healthy'
            elif len(recent_updates) >= 1:
                status['overall_status'] = 'warning'
            else:
                status['overall_status'] = 'critical'
                
        except Error as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞: {e}")
            status['overall_status'] = 'error'
        finally:
            self.disconnect_database()
        
        return status
    
    def analyze_logs(self, days: int = 7) -> Dict:
        """
        –ê–Ω–∞–ª–∏–∑ –ª–æ–≥–æ–≤ –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥
        
        Args:
            days: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
        """
        log_dir = self.config['monitoring']['log_dir']
        analysis = {
            'total_runs': 0,
            'successful_runs': 0,
            'failed_runs': 0,
            'warnings_count': 0,
            'errors_count': 0,
            'average_duration': None,
            'last_run': None,
            'performance_issues': []
        }
        
        if not os.path.exists(log_dir):
            self.logger.warning(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ª–æ–≥–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {log_dir}")
            return analysis
        
        # –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤ –ª–æ–≥–æ–≤ –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥
        cutoff_date = datetime.now() - timedelta(days=days)
        log_files = []
        
        for log_file in glob.glob(os.path.join(log_dir, "ozon_update_*.log")):
            try:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞—Ç—É –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
                filename = os.path.basename(log_file)
                date_match = re.search(r'ozon_update_(\d{8})_\d{6}\.log', filename)
                if date_match:
                    file_date = datetime.strptime(date_match.group(1), '%Y%m%d')
                    if file_date >= cutoff_date:
                        log_files.append(log_file)
            except Exception as e:
                self.logger.warning(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ –ª–æ–≥–∞ {log_file}: {e}")
        
        # –ê–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞ –ª–æ–≥–∞
        for log_file in log_files:
            try:
                run_analysis = self._analyze_single_log(log_file)
                analysis['total_runs'] += 1
                
                if run_analysis['success']:
                    analysis['successful_runs'] += 1
                else:
                    analysis['failed_runs'] += 1
                
                analysis['warnings_count'] += run_analysis['warnings']
                analysis['errors_count'] += run_analysis['errors']
                
                if run_analysis['duration']:
                    if analysis['average_duration'] is None:
                        analysis['average_duration'] = run_analysis['duration']
                    else:
                        analysis['average_duration'] = (
                            analysis['average_duration'] + run_analysis['duration']
                        ) / 2
                
                if run_analysis['start_time']:
                    if analysis['last_run'] is None or run_analysis['start_time'] > analysis['last_run']:
                        analysis['last_run'] = run_analysis['start_time']
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                threshold_minutes = self.config['monitoring']['performance_threshold_minutes']
                if run_analysis['duration'] and run_analysis['duration'] > threshold_minutes * 60:
                    analysis['performance_issues'].append({
                        'file': log_file,
                        'duration': run_analysis['duration'],
                        'start_time': run_analysis['start_time']
                    })
                    
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ª–æ–≥–∞ {log_file}: {e}")
        
        return analysis
    
    def _analyze_single_log(self, log_file: str) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –ª–æ–≥–∞"""
        analysis = {
            'success': False,
            'warnings': 0,
            'errors': 0,
            'duration': None,
            'start_time': None,
            'end_time': None
        }
        
        try:
            with open(log_file, 'r', encoding='utf-8') as f:
                content = f.read()
                
                # –ü–æ–∏—Å–∫ –º–∞—Ä–∫–µ—Ä–æ–≤ —É—Å–ø–µ—Ö–∞/–æ—à–∏–±–∫–∏
                if '–û–ë–ù–û–í–õ–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û –£–°–ü–ï–®–ù–û' in content:
                    analysis['success'] = True
                elif '–û–ë–ù–û–í–õ–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û –° –û–®–ò–ë–ö–û–ô' in content:
                    analysis['success'] = False
                
                # –ü–æ–¥—Å—á–µ—Ç –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π –∏ –æ—à–∏–±–æ–∫
                analysis['warnings'] = content.count('WARNING')
                analysis['errors'] = content.count('ERROR')
                
                # –ü–æ–∏—Å–∫ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞—á–∞–ª–∞ –∏ –æ–∫–æ–Ω—á–∞–Ω–∏—è
                start_match = re.search(r'=== –ù–∞—á–∞–ª–æ –µ–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö Ozon ===', content)
                end_match = re.search(r'=== –ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö Ozon –∑–∞–≤–µ—Ä—à–µ–Ω–æ', content)
                
                if start_match and end_match:
                    # –ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
                    lines = content.split('\n')
                    for i, line in enumerate(lines):
                        if '=== –ù–∞—á–∞–ª–æ –µ–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è' in line:
                            timestamp_match = re.search(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})', line)
                            if timestamp_match:
                                analysis['start_time'] = datetime.strptime(
                                    timestamp_match.group(1), '%Y-%m-%d %H:%M:%S'
                                )
                            break
                    
                    for i, line in enumerate(lines):
                        if '=== –ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö Ozon –∑–∞–≤–µ—Ä—à–µ–Ω–æ' in line:
                            timestamp_match = re.search(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})', line)
                            if timestamp_match:
                                analysis['end_time'] = datetime.strptime(
                                    timestamp_match.group(1), '%Y-%m-%d %H:%M:%S'
                                )
                            break
                    
                    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                    if analysis['start_time'] and analysis['end_time']:
                        duration = analysis['end_time'] - analysis['start_time']
                        analysis['duration'] = duration.total_seconds()
                        
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ –ª–æ–≥–∞ {log_file}: {e}")
        
        return analysis
    
    def generate_report(self, format: str = 'text') -> str:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ —Å–∏—Å—Ç–µ–º—ã
        
        Args:
            format: —Ñ–æ—Ä–º–∞—Ç –æ—Ç—á–µ—Ç–∞ ('text', 'json')
            
        Returns:
            –û—Ç—á–µ—Ç –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
        """
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç—á–µ—Ç–∞
        status = self.get_last_update_status()
        log_analysis = self.analyze_logs(days=7)
        
        if format == 'json':
            report_data = {
                'timestamp': datetime.now().isoformat(),
                'status': status,
                'log_analysis': log_analysis
            }
            return json.dumps(report_data, indent=2, default=str, ensure_ascii=False)
        
        # –¢–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç
        report = []
        report.append("=" * 60)
        report.append("–û–¢–ß–ï–¢ –û –°–û–°–¢–û–Ø–ù–ò–ò –°–ò–°–¢–ï–ú–´ OZON ANALYTICS")
        report.append("=" * 60)
        report.append(f"–í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        
        # –û–±—â–∏–π —Å—Ç–∞—Ç—É—Å
        status_emoji = {
            'healthy': '‚úÖ',
            'warning': '‚ö†Ô∏è',
            'critical': '‚ùå',
            'error': 'üí•',
            'unknown': '‚ùì'
        }
        
        overall_status = status['overall_status']
        report.append(f"–û–ë–©–ò–ô –°–¢–ê–¢–£–°: {status_emoji.get(overall_status, '‚ùì')} {overall_status.upper()}")
        report.append("")
        
        # –°—Ç–∞—Ç—É—Å –¥–∞–Ω–Ω—ã—Ö
        report.append("–°–¢–ê–¢–£–° –î–ê–ù–ù–´–•:")
        for data_type, data_info in status.items():
            if data_type == 'overall_status':
                continue
                
            last_update = data_info['last_update']
            records_count = data_info['records_count']
            
            if last_update:
                time_ago = datetime.now() - last_update
                hours_ago = int(time_ago.total_seconds() / 3600)
                report.append(f"  {data_type}: {records_count} –∑–∞–ø–∏—Å–µ–π, –æ–±–Ω–æ–≤–ª–µ–Ω–æ {hours_ago}—á –Ω–∞–∑–∞–¥")
            else:
                report.append(f"  {data_type}: –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
        
        report.append("")
        
        # –ê–Ω–∞–ª–∏–∑ –ª–æ–≥–æ–≤
        report.append("–ê–ù–ê–õ–ò–ó –õ–û–ì–û–í (–∑–∞ 7 –¥–Ω–µ–π):")
        report.append(f"  –í—Å–µ–≥–æ –∑–∞–ø—É—Å–∫–æ–≤: {log_analysis['total_runs']}")
        report.append(f"  –£—Å–ø–µ—à–Ω—ã—Ö: {log_analysis['successful_runs']}")
        report.append(f"  –ù–µ—É–¥–∞—á–Ω—ã—Ö: {log_analysis['failed_runs']}")
        report.append(f"  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π: {log_analysis['warnings_count']}")
        report.append(f"  –û—à–∏–±–æ–∫: {log_analysis['errors_count']}")
        
        if log_analysis['average_duration']:
            avg_minutes = int(log_analysis['average_duration'] / 60)
            report.append(f"  –°—Ä–µ–¥–Ω—è—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {avg_minutes} –º–∏–Ω—É—Ç")
        
        if log_analysis['last_run']:
            report.append(f"  –ü–æ—Å–ª–µ–¥–Ω–∏–π –∑–∞–ø—É—Å–∫: {log_analysis['last_run'].strftime('%Y-%m-%d %H:%M:%S')}")
        
        # –ü—Ä–æ–±–ª–µ–º—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        if log_analysis['performance_issues']:
            report.append("")
            report.append("–ü–†–û–ë–õ–ï–ú–´ –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò:")
            for issue in log_analysis['performance_issues']:
                duration_minutes = int(issue['duration'] / 60)
                report.append(f"  {issue['start_time']}: {duration_minutes} –º–∏–Ω—É—Ç")
        
        report.append("")
        report.append("=" * 60)
        
        return "\n".join(report)
    
    def check_alerts(self) -> List[Dict]:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ª–æ–≤–∏–π –¥–ª—è –∞–ª–µ—Ä—Ç–æ–≤
        
        Returns:
            List –∞–ª–µ—Ä—Ç–æ–≤
        """
        alerts = []
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        status = self.get_last_update_status()
        
        if status['overall_status'] == 'critical':
            alerts.append({
                'level': 'critical',
                'message': '–î–∞–Ω–Ω—ã–µ Ozon –Ω–µ –æ–±–Ω–æ–≤–ª—è–ª–∏—Å—å –±–æ–ª–µ–µ 7 –¥–Ω–µ–π',
                'timestamp': datetime.now()
            })
        elif status['overall_status'] == 'warning':
            alerts.append({
                'level': 'warning',
                'message': '–ß–∞—Å—Ç–∏—á–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö Ozon',
                'timestamp': datetime.now()
            })
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–≥–æ–≤ –Ω–∞ –æ—à–∏–±–∫–∏
        log_analysis = self.analyze_logs(days=1)  # –ó–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –¥–µ–Ω—å
        
        if log_analysis['failed_runs'] > 0:
            alerts.append({
                'level': 'error',
                'message': f'–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {log_analysis["failed_runs"]} –Ω–µ—É–¥–∞—á–Ω—ã—Ö –∑–∞–ø—É—Å–∫–æ–≤ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –¥–µ–Ω—å',
                'timestamp': datetime.now()
            })
        
        if log_analysis['errors_count'] > 10:
            alerts.append({
                'level': 'warning',
                'message': f'–í—ã—Å–æ–∫–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—à–∏–±–æ–∫ –≤ –ª–æ–≥–∞—Ö: {log_analysis["errors_count"]}',
                'timestamp': datetime.now()
            })
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        if log_analysis['performance_issues']:
            alerts.append({
                'level': 'warning',
                'message': f'–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(log_analysis["performance_issues"])} –ø—Ä–æ–±–ª–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏',
                'timestamp': datetime.now()
            })
        
        return alerts


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(description='–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–∏—Å—Ç–µ–º—ã –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è Ozon Analytics')
    parser.add_argument('--status', action='store_true', help='–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã')
    parser.add_argument('--report', choices=['text', 'json'], help='–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç—á–µ—Ç')
    parser.add_argument('--alerts', action='store_true', help='–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∞–ª–µ—Ä—Ç—ã')
    parser.add_argument('--logs', type=int, default=7, help='–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ª–æ–≥–∏ –∑–∞ N –¥–Ω–µ–π')
    
    args = parser.parse_args()
    
    monitor = OzonUpdateMonitor()
    
    if args.status:
        status = monitor.get_last_update_status()
        print(f"–û–±—â–∏–π —Å—Ç–∞—Ç—É—Å: {status['overall_status']}")
        for data_type, info in status.items():
            if data_type != 'overall_status':
                print(f"{data_type}: {info['records_count']} –∑–∞–ø–∏—Å–µ–π, –ø–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: {info['last_update']}")
    
    elif args.report:
        report = monitor.generate_report(format=args.report)
        print(report)
    
    elif args.alerts:
        alerts = monitor.check_alerts()
        if alerts:
            print("–ê–ö–¢–ò–í–ù–´–ï –ê–õ–ï–†–¢–´:")
            for alert in alerts:
                print(f"[{alert['level'].upper()}] {alert['message']}")
        else:
            print("–ê–ª–µ—Ä—Ç–æ–≤ –Ω–µ—Ç")
    
    else:
        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∫—Ä–∞—Ç–∫–∏–π —Å—Ç–∞—Ç—É—Å
        status = monitor.get_last_update_status()
        print(f"–°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã Ozon Analytics: {status['overall_status']}")


if __name__ == "__main__":
    main()